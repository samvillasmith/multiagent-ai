2025-11-01 19:42:02,734 - INFO - Starting backend server
2025-11-01 19:42:07,734 - INFO - Starting frontend UI
2025-11-01 19:46:31,296 - INFO - Starting backend server
2025-11-01 19:46:36,296 - INFO - Starting frontend UI
2025-11-01 19:46:37,581 - ERROR - Frontend UI failed to start | Error: Command '['streamlit', 'run', 'app\\frontend\\ui.py']' returned non-zero exit status 2. | File: C:\Users\Sam Ben-Yosef\Desktop\Multiagent\app\main.py | Line: 32
2025-11-01 19:46:37,582 - ERROR - Critical error in main application: Frontend UI failed to start | Error: Command '['streamlit', 'run', 'app\\frontend\\ui.py']' returned non-zero exit status 2. | File: C:\Users\Sam Ben-Yosef\Desktop\Multiagent\app\main.py | Line: 32
Traceback (most recent call last):
  File "C:\Users\Sam Ben-Yosef\Desktop\Multiagent\app\main.py", line 32, in run_frontend
    subprocess.run(["streamlit", "run", ui_path], check=True)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python313\Lib\subprocess.py", line 577, in run
    raise CalledProcessError(retcode, process.args,
                             output=stdout, stderr=stderr)
subprocess.CalledProcessError: Command '['streamlit', 'run', 'app\\frontend\\ui.py']' returned non-zero exit status 2.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Sam Ben-Yosef\Desktop\Multiagent\app\main.py", line 46, in <module>
    run_frontend()
    ~~~~~~~~~~~~^^
  File "C:\Users\Sam Ben-Yosef\Desktop\Multiagent\app\main.py", line 36, in run_frontend
    raise error
app.common.custom_exception.CustomException: Frontend UI failed to start | Error: Command '['streamlit', 'run', 'app\\frontend\\ui.py']' returned non-zero exit status 2. | File: C:\Users\Sam Ben-Yosef\Desktop\Multiagent\app\main.py | Line: 32
2025-11-01 19:47:25,452 - INFO - Starting backend server
2025-11-01 19:47:30,453 - INFO - Starting frontend UI
2025-11-01 19:54:30,483 - INFO - Starting backend server
2025-11-01 19:54:35,483 - INFO - Starting frontend UI
2025-11-01 19:55:40,440 - INFO - Starting backend server
2025-11-01 19:55:45,440 - INFO - Starting frontend UI
2025-11-01 19:59:49,189 - INFO - Starting backend server
2025-11-01 19:59:54,189 - INFO - Starting frontend UI
2025-11-01 20:01:16,356 - INFO - Sending request to backend
2025-11-01 20:01:16,596 - ERROR - Backend error
2025-11-01 20:03:00,226 - INFO - Starting backend server
2025-11-01 20:03:05,227 - INFO - Starting frontend UI
2025-11-01 20:03:45,942 - INFO - Sending request to backend
2025-11-01 20:03:45,957 - INFO - Received request for model: openai/gpt-oss-20b
2025-11-01 20:03:47,416 - ERROR - An error occurred during response generation
2025-11-01 20:03:47,418 - ERROR - Backend error
2025-11-01 20:05:04,945 - INFO - Starting backend server
2025-11-01 20:05:09,945 - INFO - Starting frontend UI
2025-11-01 20:05:32,939 - INFO - Sending request to backend
2025-11-01 20:05:32,951 - INFO - Received request for model: openai/gpt-oss-20b
2025-11-01 20:05:34,115 - ERROR - An error occurred during response generation
2025-11-01 20:05:34,117 - ERROR - Backend error
2025-11-01 20:06:39,301 - INFO - Starting backend server
2025-11-01 20:06:44,301 - INFO - Starting frontend UI
2025-11-01 20:06:58,762 - INFO - Sending request to backend
2025-11-01 20:06:58,774 - INFO - Received request for model: openai/gpt-oss-20b
2025-11-01 20:07:00,040 - ERROR - An error occurred during response generation: create_react_agent() got unexpected keyword arguments: {'state_modifier': 'test'}
2025-11-01 20:07:00,068 - ERROR - Full traceback: Traceback (most recent call last):
  File "C:\Users\Sam Ben-Yosef\Desktop\Multiagent\app\backend\api.py", line 29, in chat_endpoint
    response = get_response_from_ai_agents(
        request.model_name,
    ...<2 lines>...
        request.system_prompt
    )
  File "C:\Users\Sam Ben-Yosef\Desktop\Multiagent\app\core\ai_agent.py", line 12, in get_response_from_ai_agents
    agent = create_react_agent(
        model=llm,
        tools=tools,
        state_modifier=system_prompt
    )
  File "C:\Python313\Lib\warnings.py", line 637, in wrapper
    return arg(*args, **kwargs)
  File "C:\Users\Sam Ben-Yosef\Desktop\Multiagent\venv-cicd\Lib\site-packages\langgraph\prebuilt\chat_agent_executor.py", line 509, in create_react_agent
    raise TypeError(
        f"create_react_agent() got unexpected keyword arguments: {deprecated_kwargs}"
    )
TypeError: create_react_agent() got unexpected keyword arguments: {'state_modifier': 'test'}

2025-11-01 20:07:00,070 - ERROR - Backend error
2025-11-01 20:08:26,953 - INFO - Starting backend server
2025-11-01 20:08:31,954 - INFO - Starting frontend UI
2025-11-01 20:08:42,586 - INFO - Sending request to backend
2025-11-01 20:08:42,599 - INFO - Received request for model: llama-3.3-70b-versatile
2025-11-01 20:08:44,173 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:08:44,187 - INFO - Successfully got response from AI agent llama-3.3-70b-versatile
2025-11-01 20:08:44,188 - INFO - Successfully received response from backend
2025-11-01 20:08:48,716 - INFO - Sending request to backend
2025-11-01 20:08:48,719 - INFO - Received request for model: llama-3.1-8b-instant
2025-11-01 20:08:49,968 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:08:49,969 - INFO - Successfully got response from AI agent llama-3.1-8b-instant
2025-11-01 20:08:49,970 - INFO - Successfully received response from backend
2025-11-01 20:08:53,369 - INFO - Sending request to backend
2025-11-01 20:08:53,372 - INFO - Received request for model: openai/gpt-oss-20b
2025-11-01 20:08:54,622 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:08:54,623 - INFO - Successfully got response from AI agent openai/gpt-oss-20b
2025-11-01 20:08:54,625 - INFO - Successfully received response from backend
2025-11-01 20:09:20,778 - INFO - Sending request to backend
2025-11-01 20:09:20,782 - INFO - Received request for model: openai/gpt-oss-20b
2025-11-01 20:09:24,463 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:09:24,466 - INFO - Successfully got response from AI agent openai/gpt-oss-20b
2025-11-01 20:09:24,467 - INFO - Successfully received response from backend
2025-11-01 20:12:35,985 - INFO - Sending request to backend
2025-11-01 20:12:35,989 - INFO - Received request for model: openai/gpt-oss-20b
2025-11-01 20:12:37,754 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:12:42,176 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:12:42,178 - INFO - Successfully got response from AI agent openai/gpt-oss-20b
2025-11-01 20:12:42,179 - INFO - Successfully received response from backend
2025-11-01 20:14:13,678 - INFO - Sending request to backend
2025-11-01 20:14:13,681 - INFO - Received request for model: openai/gpt-oss-20b
2025-11-01 20:14:15,864 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:14:15,865 - INFO - Successfully got response from AI agent openai/gpt-oss-20b
2025-11-01 20:14:15,866 - INFO - Successfully received response from backend
2025-11-01 20:15:16,514 - INFO - Sending request to backend
2025-11-01 20:15:16,518 - INFO - Received request for model: openai/gpt-oss-20b
2025-11-01 20:15:17,908 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:15:22,167 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:15:22,168 - INFO - Successfully got response from AI agent openai/gpt-oss-20b
2025-11-01 20:15:22,169 - INFO - Successfully received response from backend
2025-11-01 20:16:06,968 - INFO - Sending request to backend
2025-11-01 20:16:06,972 - INFO - Received request for model: llama-3.1-8b-instant
2025-11-01 20:16:08,235 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:16:11,226 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:16:11,227 - INFO - Successfully got response from AI agent llama-3.1-8b-instant
2025-11-01 20:16:11,229 - INFO - Successfully received response from backend
2025-11-01 20:16:16,969 - INFO - Sending request to backend
2025-11-01 20:16:16,973 - INFO - Received request for model: llama-3.3-70b-versatile
2025-11-01 20:16:18,284 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:16:19,622 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-01 20:16:19,623 - INFO - Successfully got response from AI agent llama-3.3-70b-versatile
2025-11-01 20:16:19,624 - INFO - Successfully received response from backend
